{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ca5fbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "dcec5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file and create a word dictionary \n",
    "def wordsDictionary(inputfile):\n",
    "    wordsDict = dict()\n",
    "    file = open(inputfile,\"r\",encoding=\"utf8\")\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word in wordsDict:\n",
    "                wordsDict[word] +=1\n",
    "            else:\n",
    "                wordsDict[word]=1\n",
    "    return wordsDict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "6375a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the <s> and </s> into the file, and output a new file.\n",
    "def paddingFile(inputfile,outputfile):\n",
    "    inputFile = open(inputfile,\"r\")\n",
    "    outputFile = open(outputfile,\"w\")\n",
    "    for line in inputFile:\n",
    "        line = line.lower()\n",
    "        line = line.rstrip(\"\\n\")\n",
    "        line = (f\"<s> {line} </s>\\n\")\n",
    "        outputFile.write(line)\n",
    "    outputFile.close\n",
    "    return outputfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1936f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the train data. \n",
    "# Replace all words occurring in the training data once with the token <unk>\n",
    "def modifyTrainData(inputfile,outputfile,rangefile):\n",
    "    inputFile = open(inputfile,\"r\")\n",
    "    outputFile = open(outputfile,\"w\")\n",
    "    wordsDict = wordsDictionary(rangefile)\n",
    "    for line in inputFile:\n",
    "        for word in line.split():\n",
    "            if wordsDict[word]== 1:\n",
    "                outputFile.write(\" <unk>\")\n",
    "                wordsDict.pop(word)\n",
    "            else:\n",
    "                outputFile.write(\" \"+word)\n",
    "        outputFile.write(\"\\n\")\n",
    "    outputFile.close()\n",
    "    return outputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9e2bd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the test data.\n",
    "# Everyword in the test data not seen in training should be treated as <unk>.\n",
    "def modifyTestData(inputfile,outputfile,rangefile):\n",
    "    inputFile = open(inputfile,\"r\")\n",
    "    outputFile = open(outputfile,\"w\")\n",
    "    wordsDict = wordsDictionary(rangefile)\n",
    "    for line in inputFile:\n",
    "        for word in line.split():\n",
    "            if word not in wordsDict:\n",
    "                outputFile.write(\" <unk>\")\n",
    "            else:\n",
    "                outputFile.write(\" \"+word)\n",
    "        outputFile.write(\"\\n\")\n",
    "    outputFile.close()\n",
    "    return outputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "26eec956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# padding train file is \"pad_train.txt\"\n",
    "# pre-processed train file is \"pre_processed_train.txt\"\n",
    "paddingTrain = paddingFile(\"train-Spring2022.txt\",\"pad_train.txt\")\n",
    "processed_Train = modifyTrainData(paddingTrain,\"pre_processed_train.txt\",paddingTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "0360b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding test file is \"pad_test.txt\"\n",
    "# pre-processed test file is \"pre_processed_test.txt\"\n",
    "paddingTest = paddingFile(\"test.txt\",\"pad_test.txt\")\n",
    "processed_Test= modifyTestData(paddingTest,\"pre_processed_test.txt\",processed_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34202c6e",
   "metadata": {},
   "source": [
    "## Answer 1.3 Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "eb245db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: How many word types (unique words) are there in the training corpus?\n",
      "Answer: 39502\n"
     ]
    }
   ],
   "source": [
    "print('Question1: How many word types (unique words) are there in the training corpus?')\n",
    "wordsDict_Q1 = wordsDictionary(processed_Train)\n",
    "del wordsDict_Q1['<s>']\n",
    "trainWordsTypes = len(wordsDict_Q1.keys())\n",
    "print(\"Answer:\",trainWordsTypes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ae0aa62e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: How many word tokens are there in the training corpus?\n",
      "Answer: 2221290\n"
     ]
    }
   ],
   "source": [
    "print(\"Question2: How many word tokens are there in the training corpus?\")\n",
    "wordsDict_Q2 = wordsDictionary(processed_Train)\n",
    "del wordsDict_Q2['<s>']\n",
    "trainTotalTokens = sum(wordsDict_Q2.values())\n",
    "print(\"Answer:\",trainTotalTokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "649c6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of word tokens and word types in the test corpus did not occur in training \n",
    "def percentageOfMissing(inputfile):\n",
    "    paddingDictOfTest = wordsDictionary(\"pad_test.txt\")\n",
    "    paddingDictOfTrain = wordsDictionary(\"pad_train.txt\")\n",
    "    paddingDictOfTest.pop('<s>')\n",
    "    testTotalTokens = sum(paddingDictOfTest.values())\n",
    "    testTotalTypes = len(paddingDictOfTest.keys())\n",
    "    result =[]\n",
    "    inputFile = open(inputfile,\"r\",encoding=\"utf8\")\n",
    "    missDict = dict()\n",
    "    count =0\n",
    "    for line in inputFile:\n",
    "        for word in line.split():\n",
    "            if word not in paddingDictOfTrain:\n",
    "                if word in missDict:\n",
    "                    missDict[word]+=1\n",
    "                else:\n",
    "                    missDict[word]=1\n",
    "                count +=1\n",
    "    percentOfTypes = len(missDict.keys())/testTotalTypes *100;\n",
    "    percentOfTokens = sum(missDict.values())/testTotalTokens *100;\n",
    "    result = [percentOfTypes,percentOfTokens]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c3fde26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questin3:\n",
      "The percentage of word tokens in the test corpus did not occur in training:  1.806 %\n",
      "The percentage of word types in the test corpus did not occur in training:  3.926 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Questin3:\")\n",
    "print(\"The percentage of word tokens in the test corpus did not occur in training: \",\n",
    "      \"%.3f\"%percentageOfMissing(\"pad_test.txt\")[1],\"%\")\n",
    "print(\"The percentage of word types in the test corpus did not occur in training: \",\n",
    "      \"%.3f\"%percentageOfMissing(\"pad_test.txt\")[0],\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a312dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and create a Bigram types dictionary\n",
    "def BigramDictionary(inputfile):\n",
    "    wordsDict = dict()\n",
    "    file = open(inputfile,\"r\",encoding=\"utf8\")\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        words = line.split()\n",
    "        for i in range(len(words)-1):\n",
    "            wordPair = (words[i],words[i+1])\n",
    "            if wordPair in wordsDict:\n",
    "                wordsDict[wordPair] +=1\n",
    "            else:\n",
    "                wordsDict[wordPair]=1\n",
    "    return wordsDict\n",
    "\n",
    "# Read file and create a Bigram types dictionary without <s>\n",
    "def BigramDictionaryWithoutS(inputfile):\n",
    "    wordsDict = dict()\n",
    "    file = open(inputfile,\"r\",encoding=\"utf8\")\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        words = line.split()\n",
    "        for i in range(len(words)-1):\n",
    "            if (words[i] != '<s>'):\n",
    "                wordPair = (words[i],words[i+1])\n",
    "                if wordPair in wordsDict:\n",
    "                    wordsDict[wordPair] +=1\n",
    "                else:\n",
    "                    wordsDict[wordPair]=1\n",
    "    return wordsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "4bcf0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of Bigram types word tokens and word types in the test corpus did not occur in training \n",
    "def percentageOfMissingBigram(inputfile):\n",
    "    bigramOfTest = BigramDictionaryWithoutS(\"pre_processed_test.txt\")\n",
    "    bigramOfTrain = BigramDictionaryWithoutS(\"pre_processed_train.txt\")\n",
    "    testTotalTypesBigram = len(bigramOfTest.keys())\n",
    "    testTotalTokensBigram = sum(bigramOfTest.values())\n",
    "    result =[]\n",
    "    inputFile = open(inputfile,\"r\",encoding=\"utf8\")\n",
    "    missDictBigram = dict()\n",
    "    count =0\n",
    "    for line in inputFile:\n",
    "        allWords = line.split()\n",
    "        for i in range(len(allWords)-1):\n",
    "            wordPair = (allWords[i],allWords[i+1])\n",
    "            if wordPair not in bigramOfTrain:\n",
    "                if wordPair in missDictBigram:\n",
    "                    missDictBigram[wordPair]+=1\n",
    "                else:\n",
    "                    missDictBigram[wordPair]=1\n",
    "                count +=1\n",
    "\n",
    "    percentOfTypesBigram = len(missDictBigram.keys())/testTotalTypesBigram *100;\n",
    "    percentOfTokensBigram =count/testTotalTokensBigram *100;\n",
    "    result = [percentOfTypesBigram,percentOfTokensBigram]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d16468f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4:\n",
      "The percentage of bigram types in the test corpus did not occur in training:  29.512 %\n",
      "The percentage of bigram tokens in the test corpus did not occur in training:  26.752 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Question4:\")\n",
    "print(\"The percentage of bigram types in the test corpus did not occur in training: \", \n",
    "      \"%.3f\"%percentageOfMissingBigram(processed_Test)[0],\"%\")\n",
    "print(\"The percentage of bigram tokens in the test corpus did not occur in training: \", \n",
    "      \"%.3f\"%percentageOfMissingBigram(processed_Test)[1],\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "26dd574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the words list of input sentence \n",
    "def uniReplaceUNK(sen):\n",
    "    sentence = '<s> '+ sen.lower()+' </s>'\n",
    "    unigramDict_Train = wordsDictionary(processed_Train)\n",
    "    wordsOfSentence = sentence.split()\n",
    "    # replace the words not observed in training corpus to the <unk>\n",
    "    for word in wordsOfSentence:\n",
    "        if word not in unigramDict_Train:\n",
    "            wordsOfSentence = [w.replace(word,'<unk>') for w in wordsOfSentence]\n",
    "    return wordsOfSentence\n",
    "\n",
    "# Calculate the Log probability of Unigram model\n",
    "def unigramLogProb(sentencelist):\n",
    "    unigramDict_Train = wordsDictionary(processed_Train)\n",
    "    totalTokens = sum(unigramDict_Train.values())\n",
    "    sumOfProb =0.0    \n",
    "    for word in sentencelist:\n",
    "          sumOfProb += math.log(unigramDict_Train[word]/totalTokens,2)\n",
    "    return sumOfProb   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "5b4d1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bigram types word list of input sentence\n",
    "def bigramSentencePair(sentence):\n",
    "    sentence = '<s> '+ sentence.lower()+' </s>'\n",
    "    sentencelist = sentence.split()\n",
    "    bigramSentenceList = list(zip(sentencelist,sentencelist[1:]))\n",
    "    return bigramSentenceList\n",
    "\n",
    "# Calculate the Log probability of Bigram model\n",
    "def bigramLogProb(bigramSentenceList):\n",
    "    bigramDict_Train = BigramDictionary(processed_Train)\n",
    "    unigramDict_Train = wordsDictionary(processed_Train)\n",
    "    resultProb =dict()\n",
    "    bigramProb =0.0\n",
    "    bigramLogProb =0.0\n",
    "    for word in bigramSentenceList:\n",
    "        if word not in bigramDict_Train:\n",
    "            bigramProb = 0\n",
    "        else:\n",
    "            bigramProb = bigramDict_Train[word]/unigramDict_Train[word[0]] \n",
    "        resultProb[word]=bigramProb\n",
    "#     print(resultProb) \n",
    "    for i in resultProb:\n",
    "        if  resultProb[i] == 0:\n",
    "            bigramLogProb = 'undefined'\n",
    "            return bigramLogProb\n",
    "        else:\n",
    "            bigramLogProb += math.log(resultProb[i],2)\n",
    "    return bigramLogProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "783be6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Log probability of Bigram-Add-One model\n",
    "def bigramAddOneLogProb(bigramSentenceList):   \n",
    "    bigramDict_Train = BigramDictionary(processed_Train)\n",
    "    unigramDict_Train = wordsDictionary(processed_Train)\n",
    "    \n",
    "    resultProb =dict()\n",
    "    bigramProbAdd =0.0\n",
    "    bigramAddOneLogProb =0.0\n",
    "    \n",
    "    for word in bigramSentenceList:\n",
    "        if word not in bigramDict_Train:\n",
    "            bigramProbAdd = 1/(unigramDict_Train[word[0]]+ len(unigramDict_Train.keys()))\n",
    "        else:\n",
    "            bigramProbAdd = (bigramDict_Train[word] + 1)/(unigramDict_Train[word[0]]+ len(unigramDict_Train.keys()))\n",
    "        resultProb[word]= bigramProbAdd\n",
    "        \n",
    "    for i in resultProb:\n",
    "        if  resultProb[i] == 0:\n",
    "            bigramLogProb = 'undefined'\n",
    "            return bigramLogProb\n",
    "        else:\n",
    "            bigramAddOneLogProb += math.log(resultProb[i],2)\n",
    "    return bigramAddOneLogProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f052e31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 5:\n",
      "The sentence:  <s> I look forward to hearing your reply . </s>\n",
      "Log probability of Unigram model:  -95.0170792813485\n",
      "Log probability of Bigram model:  undefined\n",
      "Log probability of Bigram-Add-One model:  -97.40136026716472\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 5:\")\n",
    "sentence =\"I look forward to hearing your reply .\"\n",
    "sentenceList = uniReplaceUNK(sentence)\n",
    "bigramSentenceList= bigramSentencePair(sentence)\n",
    "\n",
    "print(\"The sentence: \",f\"<s> {sentence} </s>\")\n",
    "print(\"Log probability of Unigram model: \",unigramLogProb(sentencelist))\n",
    "print(\"Log probability of Bigram model: \", bigramLogProb(bigramSentenceList))\n",
    "print(\"Log probability of Bigram-Add-One model: \", bigramAddOneLogProb(bigramSentenceList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e9c719c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the perplexity of input sentence in each model\n",
    "def perplexity(model,sentencelist,bigramSentenceList):\n",
    "    M = len(sentencelist)\n",
    "    l = 0.0\n",
    "    if model == \"unigram\":\n",
    "        l = unigramLogProb(sentencelist)/M\n",
    "    elif model == \"bigram\":\n",
    "        if(bigramLogProb(bigramSentenceList) == 'undefined'):\n",
    "            return 'undefined'\n",
    "        else:\n",
    "            l = bigramLogProb(bigramSentenceList)/M\n",
    "    elif model == \"bigramAddOne\":\n",
    "        if(bigramAddOneLogProb(bigramSentenceList) == 'undefined'):\n",
    "            return 'undefined'\n",
    "        else:\n",
    "            l = bigramAddOneLogProb(bigramSentenceList)/M\n",
    "\n",
    "    res = math.pow(2,(-1)*l)\n",
    "    return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "514e922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 6:\n",
      "The perplexity of Unigram model:  724.9350472858843\n",
      "The perplexity of Bigram model:  undefined\n",
      "The perplexity of Bigram-Add-One model:  855.2106605432601\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 6:\")\n",
    "\n",
    "print(\"The perplexity of Unigram model: \",perplexity(\"unigram\",sentencelist,bigramSentenceList))\n",
    "print(\"The perplexity of Bigram model: \",perplexity(\"bigram\",sentencelist,bigramSentenceList))\n",
    "print(\"The perplexity of Bigram-Add-One model: \",perplexity(\"bigramAddOne\",sentencelist,bigramSentenceList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "6e4f8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the all word list of test file\n",
    "def getWordList(inputfile):\n",
    "    file = open(inputfile,\"r\",encoding=\"utf8\")\n",
    "    wordList = file.read().split()\n",
    "    return wordList\n",
    "# get the all word pair list of test file\n",
    "def getWordPair(inputfile):\n",
    "    file = open(inputfile,\"r\",encoding=\"utf8\")\n",
    "    testBigramList =[]\n",
    "    for line in file:\n",
    "        words = line.split()\n",
    "        for i in range(len(words)-1):\n",
    "            wordPair = (words[i],words[i+1])\n",
    "            testBigramList.append(wordPair)\n",
    "    return testBigramList\n",
    "\n",
    "# Calculate the perplexity of the entire test corpus under each of the models\n",
    "def testPerplexity(model,wordList,pairList):\n",
    "    testPerplexityRes = 0.0\n",
    "    if model == \"unigram\":\n",
    "         testPerplexityRes= perplexity(\"unigram\",wordList,pairList)\n",
    "    if model == \"bigram\":\n",
    "         testPerplexityRes= perplexity(\"bigram\",wordList,pairList)\n",
    "    if model == \"bigramAddOne\":\n",
    "         testPerplexityRes = perplexity(\"bigramAddOne\",wordList,pairList)\n",
    "    return  testPerplexityRes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "3e1b2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 7:\n",
      "The perplexity of Unigram model in entire test corpus:  984.4571266208084\n",
      "The perplexity of Bigram model in entire test corpus:  undefined\n",
      "The perplexity of Bigram-Add-One model in entire test corpus:  1106.5907425583841\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 7:\")\n",
    "wordList = getWordList(processed_Test)\n",
    "pairList = getWordPair(processed_Test)\n",
    "print(\"The perplexity of Unigram model in entire test corpus: \",testPerplexity(\"unigram\",wordList,pairList))\n",
    "print(\"The perplexity of Bigram model in entire test corpus: \",testPerplexity(\"bigram\",wordList,pairList ))\n",
    "print(\"The perplexity of Bigram-Add-One model in entire test corpus: \",testPerplexity(\"bigramAddOne\",wordList,pairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79cecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
